<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Talks - Thanh-Tin Nguyen</title>
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <style>
        /* Navigation Button Styles */
        nav a {
            background-color: #4CAF50; /* Green background */
            border: none;
            color: white; /* White text */
            padding: 14px 28px; /* Top and bottom padding, Left and right padding */
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px; /* Margin between buttons */
            cursor: pointer;
            border-radius: 8px; /* Rounded corners */
            transition: background-color 0.3s, box-shadow 0.3s; /* Smooth transition for hover effects */
        }

        nav a:hover {
            background-color: #45a049; /* Darker shade of green */
            box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2); /* Shadow effect on hover */
        }
    </style>
</head>
	
<body>
    <header>
        <!-- Include the same navigation as your main page -->
        <nav>
            <!-- Links to other pages -->
            <a href="index.html">Home</a>
            <!-- Add other links as needed -->
        </nav>
    </header>
    <main>
        <h1>Talks &#127763 &#127763 &#127763</h1>
		<ul style="list-style-type:square;">
		    
		    <li>
		      <a href="https://docs.google.com/presentation/d/10fMrm3c-EnHM_k98__NnK5e_lemufEmir5LoGp1s4a0/edit?usp=sharing">[Oct 3, 2023] CLIP-Event: Connecting Text and Images with Event Structures</a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/1vrFCwyjRfT2z575tpbE9AjNppzu_Psa4pykWJEu2NKg/edit?usp=sharing">[Apr 25, 2023] Zero-Shot Classification by Logical Reasoning on Natural Language
Explanations</a>
		    </li>
			  
		    <li>
		      <a href="https://docs.google.com/presentation/d/1w0haDsy9RsR0UqmDS2vJKTm-ot7PPmxpYJhPGx64lmc/edit?usp=sharing">[Mar 21, 2023] Open-Vocabulary Semantic Segmentation With Mask-Adapted CLIP </a>
		    </li>
		    <!-- 4 -->
		    <li>
		      <a href="https://docs.google.com/presentation/d/1L30yCbTVfkphIicOU0JYjBhu5z_4Me0cjcLSr2LOcu4/edit#slide=id.g20703a8677a_0_78">[Feb 14, 2023] STAIR: Learning Sparse Text and Image Representation in Grounded Tokens</a>
		    </li>
		    <!-- 3 -->
		    <li>
		      <a href="https://docs.google.com/presentation/d/1nW0lQZXS1ERXmSGtzEyBcLosnw8OsdQCGM87H1vHels/edit?usp=sharing">[Nov 22, 2022] Re-labeling ImageNet - from Single to Multi-Labels, from Global to Localized Labels</a>
		    </li>
		    <!-- 2 -->
		    <li>
		      <a href="https://docs.google.com/presentation/d/11LSAUoDC0QSogBQZrHWoM7Zc3ocMQdHc_FC8339FB2M/edit#slide=id.p">[Oct 18, 2022] Class Activation Latent Mapping - Keep CALM and Improve Visual Feature Attribution</a>
                    </li>
	            <!-- 1 -->
                    <li>
                      <a href="https://docs.google.com/presentation/d/13khKc8L5HbRJWe6wKKxpLvRkpzIPc5I1ejXi9dOgnFs/edit?usp=sharing">[Sep 20, 2022] Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation</a> </br>
                    </li>
		
		    

        	</ul>

    </main>
    <footer>
        <!-- Footer content -->
    </footer>
</body>
</html>
