<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Talks - Thanh-Tin Nguyen</title>
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <style>
        /* Navigation Button Styles */
        nav a {
            background-color: #4CAF50; /* Green background */
            border: none;
            color: white; /* White text */
            padding: 14px 28px; /* Top and bottom padding, Left and right padding */
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px; /* Margin between buttons */
            cursor: pointer;
            border-radius: 8px; /* Rounded corners */
            transition: background-color 0.3s, box-shadow 0.3s; /* Smooth transition for hover effects */
        }

        nav a:hover {
            background-color: #45a049; /* Darker shade of green */
            box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2); /* Shadow effect on hover */
        }
    	body {
            font-family: Arial, sans-serif; /* Modern font */
            padding: 20px; /* Padding around the content */
            background-color: #f4f4f9; /* Light background for easier reading */
            color: #333; /* Dark grey text color for readability */
        }
        h1 {
            color: #0056b3; /* Deep blue for titles */
            text-align: center; /* Center-align the title */
        }
        ul {
            list-style-type: none; /* Remove default list styling */
            padding: 0;
        }
        li {
            background-color: #fff; /* White background for each list item */
            margin-bottom: 10px; /* Space between items */
            padding: 15px; /* Padding inside each list item */
            border-radius: 8px; /* Rounded corners for the list items */
            box-shadow: 0 2px 5px rgba(0,0,0,0.1); /* Subtle shadow for 3D effect */
            transition: transform 0.2s; /* Smooth transform on hover */
        }
        li:hover {
            transform: translateY(-5px); /* Slight raise effect on hover */
            box-shadow: 0 4px 10px rgba(0,0,0,0.2); /* Enhanced shadow on hover */
        }
        a {
            color: #007bff; /* Bootstrap primary blue for links */
            text-decoration: none; /* No underline */
        }
        a:hover {
            text-decoration: underline; /* Underline on hover for usability */
        }
    </style>
</head>
	
<body>
    <header>
        <!-- Include the same navigation as your main page -->
        <nav>
            <!-- Links to other pages -->
            <a href="index.html">Home</a>
	    <a href="presentations.html">Presentations</a>
            <a href="projects.html">Feature Projects</a>
	    <a href="news.html">Latest News</a>
            <!-- Add other links as needed -->
        </nav>
    </header>
    <main>
        <h1>Lab Presentations &#127763 &#127763 &#127763</h1>
		<ul style="list-style-type:square;">
		    <li>
		      <a href="https://docs.google.com/presentation/d/1N3mWA0g4eUx03w9BFN42J9m13IrGunuqfUG-hRH-AbI/edit?usp=sharing">[Jul 10, 2024] Why are Visually-Grounded Language Models Bad at Image Classification</a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/1LS9GMw-jvzlryrGhFyrYUUNVZLIs39wR9bWtgqnsL-4/edit?usp=sharing">[May 16, 2024] Hierarchical Open-vocabulary Universal Image Segmentation</a>
		    </li>
			
		    <li>
		      <a href="https://docs.google.com/presentation/d/1HRSanGtjoqwYbqGUSH3oZUnhn1vpyVkKPMMP_HQ4J_Q/edit?usp=sharing">[Apr 16, 2024] GLaMM: Pixel Grounding Large Multimodal Model</a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/1-SRQz4CqDnZ5-kKF3_ToXjKqAZZikTwQAFLWMZifaAk/edit?usp=sharing">[Mar 12, 2024] Improved Zero-shot Classification by Adapting VLMs with Text Descriptions</a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/1JjP8kFnOxK90CkCIlKZaozbL9Bb4LG94TwQPelYyEX0/edit?usp=sharing">[Jan 30, 2024] Classification based on Boxes and Phrases </a><b>(Research Project)</b>
		    </li>
			
		    <li>
		      <a href="https://docs.google.com/presentation/d/16E1Be4lKNtT9u0kqQJUdxK-7IPKNbuL17PsRlkj7q94/edit?usp=sharing">[Nov 21, 2023] What does CLIP know about a red circle? Visual prompt engineering for VLMs</a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/10fMrm3c-EnHM_k98__NnK5e_lemufEmir5LoGp1s4a0/edit?usp=sharing">[Oct 3, 2023] CLIP-Event: Connecting Text and Images with Event Structures</a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/1JF96OjDiElYhzWU7Uefhnulykd4X1_NNfYtgDUC5i2w/edit?usp=sharing">[Aug 25, 2023] How does “habitat” help fine-grained bird identification? </a><b>(Research Project)</b>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/1vrFCwyjRfT2z575tpbE9AjNppzu_Psa4pykWJEu2NKg/edit?usp=sharing">[Apr 25, 2023] Zero-Shot Classification by Logical Reasoning on Natural Language Explanations</a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/1w0haDsy9RsR0UqmDS2vJKTm-ot7PPmxpYJhPGx64lmc/edit?usp=sharing">[Mar 21, 2023] Open-Vocabulary Semantic Segmentation With Mask-Adapted CLIP </a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/1L30yCbTVfkphIicOU0JYjBhu5z_4Me0cjcLSr2LOcu4/edit#slide=id.g20703a8677a_0_78">[Feb 14, 2023] STAIR: Learning Sparse Text and Image Representation in Grounded Tokens</a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/1nW0lQZXS1ERXmSGtzEyBcLosnw8OsdQCGM87H1vHels/edit?usp=sharing">[Nov 22, 2022] Re-labeling ImageNet - from Single to Multi-Labels, from Global to Localized Labels</a>
		    </li>
		    <li>
		      <a href="https://docs.google.com/presentation/d/11LSAUoDC0QSogBQZrHWoM7Zc3ocMQdHc_FC8339FB2M/edit#slide=id.p">[Oct 18, 2022] Class Activation Latent Mapping - Keep CALM and Improve Visual Feature Attribution</a>
                    </li>
                    <li>
                      <a href="https://docs.google.com/presentation/d/13khKc8L5HbRJWe6wKKxpLvRkpzIPc5I1ejXi9dOgnFs/edit?usp=sharing">[Sep 20, 2022] Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation</a> </br>
                    </li>
        	</ul>
	<h1>Ideas  &#x26A1;&#x26A1;&#x26A1;</h1>
		<ul style="list-style-type:square;">
		    <li>
		      <a href="https://docs.google.com/presentation/d/18VRhnW-AqH5BIaLsbg5Fb8J8k-J07SkQ-8NVhIDH8F8/edit?usp=sharing">[2024] Idea Proposal</a>
		    </li>
    </main>
    <footer>
        <!-- Footer content -->
    </footer>
</body>
</html>
