<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tin Nguyen-Thanh</title>
  
  <meta name="author" content="Tin Nguyen-Thanh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">

  
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tin Nguyen-Thanh</name>
              </p>
              <p>I am a Ph.D. student at <a href="https://www.auburn.edu/">Auburn University, Alabama, US</a> where I am working on XAI in multimodalities.
              </p>
              <p>
                At Auburn University, I've been working under the supervision of <a href="https://anhnguyen.me/lab/">Professor Anh Nguyen</a>.

              </p>
              <p style="text-align:center">
                <b>ngthanhtinqn@gmail.com</b> &nbsp/&nbsp
                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
				        <a href="https://ngthanhtin.github.io/blog/">Blog</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=zSAfD80AAAAJ&hl=vi">Google Scholar</a> &nbsp/&nbsp
	        <a href="https://shortscience.org/user?name=ngthanhtinqn">Short Science</a> &nbsp/&nbsp
                <a href="https://twitter.com/">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/ngthanhtin/">Github</a>&nbsp/&nbsp
	        <a href="https://github.com/ngthanhtin/ngthanhtin.github.io/blob/master/data/coding.txt">Coding</a>&nbsp/&nbsp
                <a href="https://jumpy-gopher-64d.notion.site/Artificial-Intelligence-Resource-24b21aa20eac455bbbb97b8621dde2a9">Resource</a>

                
              </p>
		
	      <p style="text-align:center">
                <b>Category:</b> 
                <a href="#news">Latest New</a> &nbsp/&nbsp
		<a href="#research">Research Interest</a> &nbsp/&nbsp
                <a href="#experience">Experience</a> &nbsp/&nbsp
                <a href="#publications">Publications</a>&nbsp/&nbsp
                <a href="#projects">Projects</a>&nbsp/&nbsp
                <a href="#talks">Talks</a>&nbsp/&nbsp
                <a href="#service">Academic Service</a>
              </p>
		    
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/tin.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/tin-circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" id="news"><tbody>
          
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Latest News</heading>
              <p>
                <h3> 2023</h3>
		  <p><a href="https://www.oreilly.com/pub/pr/3408"></a>Jun 15, 2023, got O’Reilly DEIJ scholarship.</p>
		<h3> 2022</h3>
 		  <p>Nov 1, 2022, One paper got accepted @ Expert Systems with Applications.</p>  
<!--                   <p>Jul 25, 2022, Started as a PhD student @ Auburn University.</p>
                  <p>Jan 12, 2022, Achieved 7.0 band of IELTS.</p> -->
              </p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading id="research">Research Interest</heading>
              <p>
                <ul>
		  <li>Interpretable AI.</li>
                  <li>Multimodal analysis.</li>
                  <li>Language instruction for robotics.</li>
                </ul>
                Representative papers are <span class="highlight">highlighted</span>. 
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading id="experience">Academic Experience</heading>
              <p>
                  <p>I did my <b>Master</b> at <a href="http://en.sejong.ac.kr/eng/index.do">Sejong University, 
                    Seoul, Korea</a> on Aug 2022. 
                    In this period, I was working on Deep Reinforcement Learning
                     for Instruction Following Navigation with <a href="https://scholar.google.com/citations?hl=en&user=gGfbXFIAAAAJ">Professor Yong-Guk Kim</a>.</p>
                  </p>
                  <p>I did my <b>Bachelors</b> at the <a href="https://en.hcmus.edu.vn/">Vietnam National University, 
                    The University of Science, Ho Chi Minh City </a> on Aug 2019. 
                    My thesis was about Robot Localization and Object Tracking with <a href="https://scholar.google.com/citations?hl=en&user=MskoD4gAAAAJ">Professor Ly Quoc Ngoc</a>.</p>
            </td>
          </tr>
          
<!--           <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Work Experience</heading>
              <p>
                  <p>Robotics Engineer @ OhmniLabs.</p>   
                  <p>AI Engineer @ AIOZ.</p>
            </td>
          </tr> -->

          

          

        </tbody></table>
      
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>	
		  <heading id="publications">Journal</heading>
      
		  <!-- paper  -->
      
      <tr onmouseout="hypernerf_stop()" onmouseover="hypernerf_start()"  bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/meme_ukraine.jpg' width="180", height="150">
          </div>
          <script type="text/javascript">
            function hypernerf_start() {
              document.getElementById('hypernerf_image').style.opacity = "1";
            }

            function hypernerf_stop() {
              document.getElementById('hypernerf_image').style.opacity = "0";
            }
            hypernerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="">
            <papertitle>[Under Review] Multimodal Multitask with Attention Meme Analysis</papertitle>
          </a>
          <br>
          <a href=""><strong>Thanh Tin Nguyen</strong></a>,
          <a href="">Nhat Truong Pham</a>,
          <a href="">Yong-Guk Kim</a> <br>
          <br>
          <em> IEEE Transactions on Affective Computing,</em> 2022
          <br>
          <a href="">Project Page</a> /
          <a href="https://github.com/ngthanhtin/X-MEME">Code</a> /
          <a href="">Paper</a>
          <p></p>
          <p>This study proposes an attention-based module for analyzing the sentiment and emotion of memes.</p>
        </td>
      </tr> 
      
      <tr onmouseout="hypernerf_stop()" onmouseover="hypernerf_start()"  bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/vizdoom_instruction.gif' width="180", height="100">
          </div>
          <script type="text/javascript">
            function hypernerf_start() {
              document.getElementById('hypernerf_image').style.opacity = "1";
            }

            function hypernerf_stop() {
              document.getElementById('hypernerf_image').style.opacity = "0";
            }
            hypernerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="">
            <papertitle>[Under Review] Coarse-To-Fine Fusion for Language Grounding in 3D Navigation</papertitle>
          </a>
          <br>
          <a href=""><strong>Thanh Tin Nguyen</strong></a>,
	  <a href="https://vohoanganh.github.io/"><strong>Anh H. Vo</strong></a>,
	  <a href="">Soo-Mi Choi</a>,
          <a href="">Yong-Guk Kim</a> <br>
          <br>
          <em> Knowledge-based Systems (KBS),</em> 2022
          <br>
          <a href="https://youtu.be/rwODCJFM1SY">Video</a> /
          <a href="https://github.com/ngthanhtin/AE_VLN_Vizdoom">Code</a> /
          <a href="">Paper</a>
          <p></p>
          <p>This study proposes a coarse-to-fine fusion module between vision and language. This will help an agent learn a joint representation while navigating in a virtual environment.</p>
        </td>
      </tr> 

<!-- 		  <tr onmouseout="hypernerf_stop()" onmouseover="hypernerf_start()" bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/vizdoom_instruction_two_goals.gif' width="180">
          </div>
          <script type="text/javascript">
            function hypernerf_start() {
              document.getElementById('hypernerf_image').style.opacity = "1";
            }

            function hypernerf_stop() {
              document.getElementById('hypernerf_image').style.opacity = "0";
            }
            hypernerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="">
            <papertitle>[Under Review] Language Grounding Network with Fourier Transform for Multi-Goal 3D Navigation</papertitle>
          </a>
          <br>
          <a href=""><strong>Thanh Tin Nguyen</strong></a>,
          <a href="">Ngoc Duy Nguyen</a>,
          <a href="">Chee Peng Lim</a>,
          <a href="">Asim Bhatti</a>,
          <a href="">Yong-Guk Kim</a> <br>
          <br>
          <em>Expert System with Applications (ESWA)</em>, 14, December, 2021
          <br>
          <a href="https://youtu.be/uF2CtWHsPfk">Video</a>/
          <a href="">Code</a> /
          <a href="">Paper</a>
          <p></p>
          <p>This study outlines a fusion module based on Fourier Transform which helps an agent navigate in multi-goal 3D environments.</p>
        </td>
      </tr>  -->
	      
	<tr onmouseout="hypernerf_stop()" onmouseover="hypernerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='hypernerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/hypernerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/aivn_covid.png' width="180", height="100">
              </div>
              <script type="text/javascript">
                function hypernerf_start() {
                  document.getElementById('hypernerf_image').style.opacity = "1";
                }

                function hypernerf_stop() {
                  document.getElementById('hypernerf_image').style.opacity = "0";
                }
                hypernerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>[Accepted] Fruit-CoV: An Efficient Vision-based Framework for Speedy Detection and Diagnosis of SARS-CoV-2 Infections Through Recorded Cough Sounds</papertitle>
              </a>
              <br>
							<a href="">Long H. Nguyen</a>,
							<a href="">Nhat Truong Pham</a>,
							<a href="">Van Huong Do</a>,
							<a href="">Liu Tai Nguyen</a>,
							<a href=""><strong>Thanh Tin Nguyen</strong></a>,
							<a href="">Van Dung Do</a>,
							<a href="">Hai Nguyen</a>, 
							<a href="">Ngoc Duy Nguyen</a> <br>
              <br>
              <font color="red"><strong>(Challenge 1st)</strong></font> <em>Expert System with Applications (ESWA)</em>, 1, November, 2022
              <br>
              <a href="https://www.covid.aihub.vn/organizers">Link Challenge</a> /
              <a href="https://www.sciencedirect.com/science/article/pii/S0957417422022308">Paper</a>
              <p></p>
              <p>Introducing Fruit-CoV, a two-stage vision framework, which is capable of detecting SARS-CoV-2 infections through recorded cough sounds. In this challenge, we won <b>100mil VND (~ $4275)</b> for the 1st place.</p>
            </td>
          </tr>

          <tr onmouseout="hypernerf_stop()" onmouseover="hypernerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='hypernerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/hypernerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/stereo_localization.gif' width="180", height="155">
              </div>
              <script type="text/javascript">
                function hypernerf_start() {
                  document.getElementById('hypernerf_image').style.opacity = "1";
                }

                function hypernerf_stop() {
                  document.getElementById('hypernerf_image').style.opacity = "0";
                }
                hypernerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>A New Framework of Moving Object Tracking Based on Object
					Detection-Tracking with Removal of Moving Features using Stereo Camera and IMU</papertitle>
              </a>
              <br>
							<a href=""><strong>Nguyen Thanh Tin</strong></a>,
							<a href="">Ly Quoc Ngoc</a>, 
							<a href="">Le Bao Tuan</a> <br>
              <br>
              <em>International Journal of Advanced Computer Science and Applications (SAI)</em>, 14, April, 2020
              <br>
              <a href="https://youtu.be/3n9yK8TkvFY">Video 1</a> /
			        <a href="https://youtu.be/CYT-qYVahKc">Video 2</a> / 
			        <a href="https://youtu.be/B69EYVtIKCo">Video 3</a> /
              <a href="https://thesai.org/Publications/ViewPaper?Volume=11&Issue=4&Code=IJACSA&SerialNo=6">Paper</a>
              <p></p>
              <p>Applying Yolo3 to Particle Filter to enhance its speed and accuracy, 
                furthermore, an end-to-end localization framework using a stereo camera and IMU in the unknown environment.</p>
            </td>
          </tr> 
		</tbody></table>
		  
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
		  <heading>Workshop / Challenge</heading>

<!--         <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/cxr.png' width="190">
            </div>
            <script type="text/javascript">
              function mipnerf_start() {
                document.getElementById('mipnerf_image').style.opacity = "1";
              }

              function mipnerf_stop() {
                document.getElementById('mipnerf_image').style.opacity = "0";
              }
              mipnerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="">
              <papertitle>Artificial Intelligence for Covid-19 prognosis</papertitle>
            </a>
            <br>
            <strong>Nguyen Thanh Tin</strong>
            <br>
            <font color="red"><strong>(Hackathon)</strong></font> <em>Covid CXR Hackathon</em>, 2021 &nbsp 
            <br>
            <a href="https://ai4covid-hackathon.it/">Link Challenge</a> /
            <a href="https://ngthanhtin.github.io/blog/challenge/2022-1-1-covidcxr2022/">Project Page</a> /
            <a href="https://github.com/ngthanhtin/Covid_CXR_Hackathon">Code</a>
            <p></p>
            <p>Achieved 9/20 on the private leaderboard.</p>
          </td>
        </tr> -->

        <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/meme.jpg' width="190">
            </div>
            <script type="text/javascript">
              function mipnerf_start() {
                document.getElementById('mipnerf_image').style.opacity = "1";
              }

              function mipnerf_stop() {
                document.getElementById('mipnerf_image').style.opacity = "0";
              }
              mipnerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="">
              <papertitle>HCILab at Memotion 2.0 2022: Analysis of sentiment, emotion and intensity of emotion classes from meme images using single and multi modalities</papertitle>
            </a>
            <br>
            <strong>Nguyen Thanh Tin</strong>, Nhat Truong Pham, Yong-Guk Kim, et. al,. 
            <br>
            <font color="red"><strong>(Workshop)</strong></font> <em>First Workshop on ​Multimodal Fact-Checking and Hate Speech Detection AAAI 2022</em>, 2021 &nbsp 
            <br>
            <a href="http://ceur-ws.org/Vol-3199/paper12.pdf">Paper</a> /
            <a href="https://aiisc.ai/defactify/memotion_2.html">Link Challenge</a> /
            <a href="https://ngthanhtin.github.io/blog/challenge/2021-11-15-memotion2/">Project Page</a> /
            <a href="https://github.com/ngthanhtin/Memotion2_AAAI_WS_2022">Code</a>
            <p></p>
            <p>Achieved 1st on the public leaderboard, applying SAN, multihop, CNNRoBerta as multimodalities, and Only Text and Image as Single modalities.</p>
          </td>
        </tr> 

          <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vlsp.gif" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/image_captioning_vlsp.png' width="200", height="140">
              </div>
              <script type="text/javascript">
                function mipnerf_start() {
                  document.getElementById('mipnerf_image').style.opacity = "1";
                }

                function mipnerf_stop() {
                  document.getElementById('mipnerf_image').style.opacity = "0";
                }
                mipnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Image Captioning Using Swin Transformer Encoder and LSTM Attention Decoder</papertitle>
              </a>
              <br>
              <strong>Nguyen Thanh Tin</strong>
              <br>
              <font color="red"><strong>(Workshop 3rd and)</strong></font> <em>VLSP - vieCap4H Challenge: Automatic image caption generation for
                 healthcare domains in Vietnamese (Oral presentation)</em>, 25, October, 2021 &nbsp 
              <br>
              <br>
              <font color="red"><strong>(VNU Journal of Science (JCSCE))</strong></font> <em>vieCap4H - VLSP 2021: Vietnamese Image Captioning for 
                Healthcare Domain using Swin Transformer and Attention-based LSTM</em>, 5, May, 2022 &nbsp 
              <br>
              <a href="https://jcsce.vnu.edu.vn/index.php/jcsce/article/view/369" type="application/pdf">Paper</a> /
			        <a href="https://vlsp.org.vn/vlsp2021/eval/vieCap4H">Link Challenge</a> /
              <a href="https://ngthanhtin.github.io/blog/challenge/2021-11-15-vietnameseimagecaptioningvlsp/">Project Page</a> /
              <a href="https://github.com/ngthanhtin/VLSP_ImageCaptioning">Code</a>
              <p></p>
              <p><b>[Most interesting discussed idea award] </b> Achieved 3rd on the private leaderboard, applying Swin Transformer as the Encoder (and other types), and LSTM Attention as the Decoder.</p>
              <p>Choosen to be in the Special Issue of VNU Journal of Science <a href="https://jcsce.vnu.edu.vn/index.php/jcsce">(JCSCE)</a></p>
            </td>
          </tr> 


        </tbody>
      </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
		  <heading id="projects">Feature Projects</heading>

        <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/mot.gif' width="190">
            </div>
            <script type="text/javascript">
              function mipnerf_start() {
                document.getElementById('mipnerf_image').style.opacity = "1";
              }

              function mipnerf_stop() {
                document.getElementById('mipnerf_image').style.opacity = "0";
              }
              mipnerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="">
              <papertitle>Multiple Object Tracking</papertitle>
            </a>
            <br>
            <strong>Nguyen Thanh Tin</strong> </br>
            <a href="https://ngthanhtin.github.io/blog/tracking/2021-02-04-multiple-object-tracking-with-kalman-filter/">Project Page</a> /
            <a href="https://github.com/ngthanhtin/Muiltiple-Object-Tracking">Code</a>
            <p></p>
            <p>Implement by C++. Project using Background Subtraction Method, Kalman Filter, and Hungary Algorithm.</p>
          </td>
        </tr>
        
<!--         <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/occupancy_map.gif' width="190">
            </div>
            <script type="text/javascript">
              function mipnerf_start() {
                document.getElementById('mipnerf_image').style.opacity = "1";
              }

              function mipnerf_stop() {
                document.getElementById('mipnerf_image').style.opacity = "0";
              }
              mipnerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="">
              <papertitle>Basic Probabilistic Robotics</papertitle>
            </a>
            <br>
            <strong>Nguyen Thanh Tin</strong> </br>
            <a href="https://ngthanhtin.github.io/blog/">Project Page</a> /
            <a href="https://github.com/ngthanhtin/Basic_Probabilistic_Robotics">Code</a>
            <p></p>
            <p>This project is to implement basic robotics algorithms such as Localization, SLAM, Path Finding, etc.</p>
          </td>
        </tr> -->
        
        <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/ma_il.gif' width="190">
            </div>
            <script type="text/javascript">
              function mipnerf_start() {
                document.getElementById('mipnerf_image').style.opacity = "1";
              }

              function mipnerf_stop() {
                document.getElementById('mipnerf_image').style.opacity = "0";
              }
              mipnerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="">
              <papertitle>Multi-Agent for Instruction Following Nagivation</papertitle>
            </a>
            <br>
            <strong>Nguyen Thanh Tin</strong> </br>
            <a href="https://ngthanhtin.github.io/blog/">Project Page</a> /
            <a href="https://github.com/ngthanhtin/Instruction-Navigation-MultiRobot">Code</a>
            <p></p>
            <p>Multi-Agent (2 robots) for Instruction Following Navigation task.</p>
          </td>
        </tr>
        
<!--         <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/drone_navigation.gif' width="190">
            </div>
            <script type="text/javascript">
              function mipnerf_start() {
                document.getElementById('mipnerf_image').style.opacity = "1";
              }

              function mipnerf_stop() {
                document.getElementById('mipnerf_image').style.opacity = "0";
              }
              mipnerf_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="">
              <papertitle>Drone Nagivation</papertitle>
            </a>
            <br>
            <strong>Nguyen Thanh Tin</strong> </br>
            <a href="https://ngthanhtin.github.io/blog/">Project Page</a> /
            <a href="https://github.com/ngthanhtin/DodgeDrone_2022">Code</a>
            <p></p>
            <p>Implementing Drone Navigation task in DodgeDrone Environment using Soft Actor-Critic (SAC) algorithm.</p>
          </td>
        </tr> -->

        </tbody></table>
	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
     		<tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading id="talks">Talks &#127763 &#127763 &#127763</heading>
                  <p>
                    <!-- In our lab, we have weekly meetings where the members either present their research or review a paper.  -->
                    Here, I list down the papers that I have reviewed/presented:
                  </p>

                  <ul style="list-style-type:square;">
		    <li>
		      <a href="https://docs.google.com/presentation/d/1vrFCwyjRfT2z575tpbE9AjNppzu_Psa4pykWJEu2NKg/edit?usp=sharing">[Apr 25, 2023] Zero-Shot Classification by Logical Reasoning on Natural Language
Explanations</a>
		    </li>
			  
		    <li>
		      <a href="https://docs.google.com/presentation/d/1w0haDsy9RsR0UqmDS2vJKTm-ot7PPmxpYJhPGx64lmc/edit?usp=sharing">[Mar 21, 2023] Open-Vocabulary Semantic Segmentation With Mask-Adapted CLIP </a>
		    </li>
		    <!-- 4 -->
		    <li>
		      <a href="https://docs.google.com/presentation/d/1L30yCbTVfkphIicOU0JYjBhu5z_4Me0cjcLSr2LOcu4/edit#slide=id.g20703a8677a_0_78">[Feb 14, 2023] STAIR: Learning Sparse Text and Image Representation in Grounded Tokens</a>
		    </li>
		    <!-- 3 -->
		    <li>
		      <a href="https://docs.google.com/presentation/d/1nW0lQZXS1ERXmSGtzEyBcLosnw8OsdQCGM87H1vHels/edit?usp=sharing">[Nov 22, 2022] Re-labeling ImageNet - from Single to Multi-Labels, from Global to Localized Labels</a>
		    </li>
		    <!-- 2 -->
		    <li>
		      <a href="https://docs.google.com/presentation/d/11LSAUoDC0QSogBQZrHWoM7Zc3ocMQdHc_FC8339FB2M/edit#slide=id.p">[Oct 18, 2022] Class Activation Latent Mapping - Keep CALM and Improve Visual Feature Attribution</a>
                    </li>
	            <!-- 1 -->
                    <li>
                      <a href="https://docs.google.com/presentation/d/13khKc8L5HbRJWe6wKKxpLvRkpzIPc5I1ejXi9dOgnFs/edit?usp=sharing">[Sep 20, 2022] Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation</a> </br>
                    </li>
		
		    

                  </ul>

              </td>
            </tr>

        </tbody></table>	
	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
     		<tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading id="service">Academic Service</heading>
                  

                  <ul style="list-style-type:square;">
                    <!-- 1 -->
                    <li>
                      <a href="">[Aug, 2022 - May, 2023] Teacher at K-6 AI Club:
                         AI Club for children around the elementary-school-age (K-6) to learn math, coding, robotics, and artificial intelligence. This is a completely FREE, voluntary, educational event. Supported by Auburn University and an NSF CAREER award.</a>
                    </li>

                  </ul>

              </td>
            </tr>

        </tbody></table>

        <hr>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=faCcSvsbzaN24Thb3pbWgNeoMhkjEmdnhVxqV62bvyI&cl=ffffff&w=a"></script></td>
            <td width="75%" valign="center">
              <br>
              <p style="text-align:right;">Nguyen Thanh Tin</a></p>
            </td>
          </tr>
          
        </tbody></table>


      </td>
    </tr>
  </table>

  
  
  



</body>

</html>
